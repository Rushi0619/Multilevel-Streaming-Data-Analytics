from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import (
    Tokenizer, StopWordsRemover,
    HashingTF, IDF, StringIndexer
)
from pyspark.ml.classification import LogisticRegression

spark = SparkSession.builder \
    .appName("Spark-ML-Sentiment-Training") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

# -----------------------------
# Load Level-2 data
# -----------------------------
df = spark.read.parquet("level2_output")

df = df.select("Headline", "Sentiment") \
       .where("Headline IS NOT NULL AND Sentiment IS NOT NULL")

# -----------------------------
# Feature pipeline
# -----------------------------
tokenizer = Tokenizer(inputCol="Headline", outputCol="words")
remover = StopWordsRemover(inputCol="words", outputCol="filtered")
hashingTF = HashingTF(inputCol="filtered", outputCol="rawFeatures", numFeatures=1000)
idf = IDF(inputCol="rawFeatures", outputCol="features")

# -----------------------------
# Label encoding
# -----------------------------
label_indexer = StringIndexer(
    inputCol="Sentiment",
    outputCol="label",
    handleInvalid="skip"
)

# -----------------------------
# ML model
# -----------------------------
lr = LogisticRegression(
    maxIter=10,
    regParam=0.01
)

pipeline = Pipeline(stages=[
    tokenizer,
    remover,
    hashingTF,
    idf,
    label_indexer,
    lr
])

# -----------------------------
# Train model
# -----------------------------
model = pipeline.fit(df)

# -----------------------------
# Predict
# -----------------------------
predictions = model.transform(df)

predictions.select(
    "Headline",
    "Sentiment",
    "prediction",
    "probability"
).show(5, truncate=False)

# -----------------------------
# Store results
# -----------------------------
predictions.select(
    "Headline",
    "Sentiment",
    "prediction",
    "probability"
).write.mode("overwrite").parquet("level3_ml_predictions")

spark.stop()
